{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Speech to Text and Sentiment Analysis on Audio Files Automation\n",
    "    <h4>Azure Cognitive Servisler içerisinde yer alan Speech servisi ile örnek bir sesten metne dönüşüm scripti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congitive Servisler Dökümantasyonu: https://docs.microsoft.com/en-us/azure/cognitive-services/\n",
    "\n",
    "**Speech Servisi**\n",
    "\n",
    "Speech Servisleri Dökümantasyonu: https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/\n",
    "\n",
    "Speech to Text Dökümantasyonu: https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/speech-to-text\n",
    "\n",
    "Batch transcription REST API: https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/batch-transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "import requests\n",
    "import time\n",
    "import swagger_client as cris_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG,\n",
    "        format=\"%(asctime)s %(message)s\", datefmt=\"%m/%d/%Y %I:%M:%S %p %Z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Portal üzerinde oluşturulan Speech servisine ait key ve region girilmelidir.\n",
    "\n",
    "Ses dosyaları Azure üzerinde bir Blob'da olmalıdır. Tek ses dosyası için dönüşüm yapılacaksa RECORDINGS_BLOB_URI, birden çok ses dosyası için dönüşüm yapılacaksa RECORDINGS_CONTAINER_URI sağlanmalıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your subscription key and region for the speech service\n",
    "SUBSCRIPTION_KEY = \"your_key\"\n",
    "SERVICE_REGION = \"your_region\"\n",
    "\n",
    "NAME = \"Simple transcription\"\n",
    "DESCRIPTION = \"Simple transcription description\"\n",
    "\n",
    "LOCALE = \"tr-TR\"\n",
    "RECORDINGS_BLOB_URI = \"<Your SAS Uri to a container of audio file>\"\n",
    "\n",
    "# Provide the uri of a container with audio files for transcribing all of them with a single request\n",
    "RECORDINGS_CONTAINER_URI = \"<Your SAS Uri to a container of audio files>\"\n",
    "\n",
    "# Set model information when doing transcription with custom models\n",
    "MODEL_REFERENCE = None  # guid of a custom model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_from_single_blob(uri, properties):\n",
    "    \"\"\"\n",
    "    Transcribe a single audio file located at `uri` using the settings specified in `properties`\n",
    "    using the base model for the specified locale.\n",
    "    \"\"\"\n",
    "    transcription_definition = cris_client.Transcription(\n",
    "        display_name=NAME,\n",
    "        description=DESCRIPTION,\n",
    "        locale=LOCALE,\n",
    "        content_urls=[uri],\n",
    "        properties=properties\n",
    "    )\n",
    "\n",
    "    return transcription_definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_with_custom_model(api, uri, properties):\n",
    "    \"\"\"\n",
    "    Transcribe a single audio file located at `uri` using the settings specified in `properties`\n",
    "    using the base model for the specified locale.\n",
    "    \"\"\"\n",
    "    # Model information (ADAPTED_ACOUSTIC_ID and ADAPTED_LANGUAGE_ID) must be set above.\n",
    "    if MODEL_REFERENCE is None:\n",
    "        logging.error(\"Custom model ids must be set when using custom models\")\n",
    "        sys.exit()\n",
    "\n",
    "    model = api.get_model(MODEL_REFERENCE)\n",
    "\n",
    "    transcription_definition = cris_client.Transcription(\n",
    "        display_name=NAME,\n",
    "        description=DESCRIPTION,\n",
    "        locale=LOCALE,\n",
    "        content_urls=[uri],\n",
    "        model=model,\n",
    "        properties=properties\n",
    "    )\n",
    "\n",
    "    return transcription_definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_from_container(uri, properties):\n",
    "    \"\"\"\n",
    "    Transcribe all files in the container located at `uri` using the settings specified in `properties`\n",
    "    using the base model for the specified locale.\n",
    "    \"\"\"\n",
    "    transcription_definition = cris_client.Transcription(\n",
    "        display_name=NAME,\n",
    "        description=DESCRIPTION,\n",
    "        locale=LOCALE,\n",
    "        content_container_url=uri,\n",
    "        properties=properties\n",
    "    )\n",
    "\n",
    "    return transcription_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _paginate(api, paginated_object):\n",
    "    \"\"\"\n",
    "    The autogenerated client does not support pagination. This function returns a generator over\n",
    "    all items of the array that the paginated object `paginated_object` is part of.\n",
    "    \"\"\"\n",
    "    yield from paginated_object.values\n",
    "    typename = type(paginated_object).__name__\n",
    "    auth_settings = [\"apiKeyHeader\", \"apiKeyQuery\"]\n",
    "    while paginated_object.next_link:\n",
    "        link = paginated_object.next_link[len(api.api_client.configuration.host):]\n",
    "        paginated_object, status, headers = api.api_client.call_api(link, \"GET\",\n",
    "            response_type=typename, auth_settings=auth_settings)\n",
    "\n",
    "        if status == 200:\n",
    "            yield from paginated_object.values\n",
    "        else:\n",
    "            raise Exception(f\"could not receive paginated data: status {status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_transcriptions(api):\n",
    "    \"\"\"\n",
    "    Delete all transcriptions associated with your speech resource.\n",
    "    \"\"\"\n",
    "    logging.info(\"Deleting all existing completed transcriptions.\")\n",
    "\n",
    "    # get all transcriptions for the subscription\n",
    "    transcriptions = list(_paginate(api, api.get_transcriptions()))\n",
    "\n",
    "    # Delete all pre-existing completed transcriptions.\n",
    "    # If transcriptions are still running or not started, they will not be deleted.\n",
    "    for transcription in transcriptions:\n",
    "        transcription_id = transcription._self.split('/')[-1]\n",
    "        logging.debug(f\"Deleting transcription with id {transcription_id}\")\n",
    "        try:\n",
    "            api.delete_transcription(transcription_id)\n",
    "        except cris_client.rest.ApiException as exc:\n",
    "            logging.error(f\"Could not delete transcription {transcription_id}: {exc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe():\n",
    "    logging.info(\"Starting transcription client...\")\n",
    "\n",
    "    # configure API key authorization: subscription_key\n",
    "    configuration = cris_client.Configuration()\n",
    "    configuration.api_key[\"Ocp-Apim-Subscription-Key\"] = SUBSCRIPTION_KEY\n",
    "    configuration.host = f\"https://{SERVICE_REGION}.api.cognitive.microsoft.com/speechtotext/v3.0\"\n",
    "\n",
    "    # create the client object and authenticate\n",
    "    client = cris_client.ApiClient(configuration)\n",
    "\n",
    "    # create an instance of the transcription api class\n",
    "    api = cris_client.DefaultApi(api_client=client)\n",
    "\n",
    "    # Specify transcription properties by passing a dict to the properties parameter. See\n",
    "    # https://docs.microsoft.com/azure/cognitive-services/speech-service/batch-transcription#configuration-properties\n",
    "    # for supported parameters.\n",
    "    properties = {\n",
    "        \"punctuationMode\": \"DictatedAndAutomatic\",\n",
    "        \"profanityFilterMode\": \"Masked\",\n",
    "        \"wordLevelTimestampsEnabled\": True,\n",
    "        \"diarizationEnabled\": True,\n",
    "        # \"destinationContainerUrl\": \"<results container>\",\n",
    "        # \"timeToLive\": \"PT1H\"\n",
    "    }\n",
    "\n",
    "    # Use base models for transcription. Comment this block if you are using a custom model.\n",
    "    transcription_definition = transcribe_from_single_blob(RECORDINGS_BLOB_URI, properties)\n",
    "\n",
    "    # Uncomment this block to use custom models for transcription.\n",
    "    # transcription_definition = transcribe_with_custom_model(api, RECORDINGS_BLOB_URI, properties)\n",
    "\n",
    "    # Uncomment this block to transcribe all files from a container.\n",
    "    # transcription_definition = transcribe_from_container(RECORDINGS_CONTAINER_URI, properties)\n",
    "\n",
    "    created_transcription, status, headers = api.create_transcription_with_http_info(transcription=transcription_definition)\n",
    "\n",
    "    # get the transcription Id from the location URI\n",
    "    transcription_id = headers[\"location\"].split(\"/\")[-1]\n",
    "\n",
    "    # Log information about the created transcription. If you should ask for support, please\n",
    "    # include this information.\n",
    "    logging.info(f\"Created new transcription with id '{transcription_id}' in region {SERVICE_REGION}\")\n",
    "\n",
    "    logging.info(\"Checking status.\")\n",
    "\n",
    "    completed = False\n",
    "\n",
    "    while not completed:\n",
    "        # wait for 5 seconds before refreshing the transcription status\n",
    "        time.sleep(5)\n",
    "\n",
    "        transcription = api.get_transcription(transcription_id)\n",
    "        logging.info(f\"Transcriptions status: {transcription.status}\")\n",
    "\n",
    "        if transcription.status in (\"Failed\", \"Succeeded\"):\n",
    "            completed = True\n",
    "\n",
    "        if transcription.status == \"Succeeded\":\n",
    "            pag_files = api.get_transcription_files(transcription_id)\n",
    "            for file_data in _paginate(api, pag_files):\n",
    "                if file_data.kind != \"Transcription\":\n",
    "                    continue\n",
    "\n",
    "                audiofilename = file_data.name\n",
    "                results_url = file_data.links.content_url\n",
    "                results = requests.get(results_url)\n",
    "                logging.info(f\"Results for {audiofilename}:\\n{results.content.decode('utf-8')}\")\n",
    "        elif transcription.status == \"Failed\":\n",
    "            logging.info(f\"Transcription failed: {transcription.properties.error.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    transcribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
