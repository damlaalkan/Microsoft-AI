{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "second-module",
   "metadata": {},
   "source": [
    "Use the Text Analytics client library and REST API\n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/quickstarts/client-libraries-rest-api?pivots=programming-language-python&tabs=version-3-1#key-phrase-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azure-ai-textanalytics --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"0d987ee29887432c8dbc14c2fc0fcc1a\"\n",
    "endpoint = \"https://textanalyticshuma.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticateClient():\n",
    "    credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "        endpoint=endpoint, credential=credential)\n",
    "    return text_analytics_client\n",
    "client = authenticateClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-orleans",
   "metadata": {},
   "source": [
    "VERSION: 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-negative",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#V3.1\n",
    "def sentiment_analysis_example(client):\n",
    "\n",
    "    documents = [\"te amo mucho.\"]\n",
    "    response = client.analyze_sentiment(documents=documents)[0]\n",
    "    print(\"Document Sentiment: {}\".format(response.sentiment))\n",
    "    print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "        response.confidence_scores.positive,\n",
    "        response.confidence_scores.neutral,\n",
    "        response.confidence_scores.negative,\n",
    "    ))\n",
    "    for idx, sentence in enumerate(response.sentences):\n",
    "        print(\"Sentence: {}\".format(sentence.text))\n",
    "        print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n",
    "        print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "            sentence.confidence_scores.positive,\n",
    "            sentence.confidence_scores.neutral,\n",
    "            sentence.confidence_scores.negative,\n",
    "        ))\n",
    "          \n",
    "sentiment_analysis_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-cotton",
   "metadata": {},
   "source": [
    "VERSION: 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "#V3.0\n",
    "def sentiment_analysis_example(client):\n",
    "\n",
    "    documents = [\"Seni çok seviyorum.\"]\n",
    "    response = client.analyze_sentiment(documents = documents)[0]\n",
    "    print(\"Document Sentiment: {}\".format(response.sentiment))\n",
    "    print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "        response.confidence_scores.positive,\n",
    "        response.confidence_scores.neutral,\n",
    "        response.confidence_scores.negative,\n",
    "    ))\n",
    "    for idx, sentence in enumerate(response.sentences):\n",
    "        print(\"Sentence: {}\".format(sentence.text))\n",
    "        print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n",
    "        print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "            sentence.confidence_scores.positive,\n",
    "            sentence.confidence_scores.neutral,\n",
    "            sentence.confidence_scores.negative,\n",
    "        ))\n",
    "          \n",
    "sentiment_analysis_example(client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-career",
   "metadata": {},
   "source": [
    "VERSION: 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#V2.x\n",
    "def sentiment():\n",
    "    \n",
    "    client = authenticateClient()\n",
    "\n",
    "    try:\n",
    "        documents = [\n",
    "            {\"id\": \"1\", \"language\": \"en\", \"text\": \"I had the best day of my life.\"},\n",
    "            {\"id\": \"2\", \"language\": \"en\",\n",
    "                \"text\": \"This was a waste of my time. The speaker put me to sleep.\"},\n",
    "            {\"id\": \"3\", \"language\": \"es\", \"text\": \"No tengo dinero ni nada que dar...\"},\n",
    "            {\"id\": \"4\", \"language\": \"tur\",\n",
    "                \"text\": \"seni çok seviyorum.\"}\n",
    "        ]\n",
    "\n",
    "        response = client.analyze_sentiment(documents=documents)\n",
    "        for document in response:\n",
    "            print(\"Document Id: \", document.id, \", Sentiment: \", document.sentiment)\n",
    "            score = document.confidence_scores\n",
    "            print(\"\\tConfidence Scores: \")\n",
    "            print(\"\\t\\tNegative: {:.2f}\\tNeutral: {:.2f}\\tPositive: {:.2f}\"\n",
    "                  .format(score.negative, score.neutral, score.positive))\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_with_opinion_mining_example(client):\n",
    "\n",
    "    documents = [\n",
    "        \"The food and service were unacceptable, but the concierge were nice\"\n",
    "    ]\n",
    "\n",
    "    result = client.analyze_sentiment(documents, show_opinion_mining=True)\n",
    "    doc_result = [doc for doc in result if not doc.is_error]\n",
    "\n",
    "    positive_reviews = [doc for doc in doc_result if doc.sentiment == \"positive\"]\n",
    "    negative_reviews = [doc for doc in doc_result if doc.sentiment == \"negative\"]\n",
    "\n",
    "    positive_mined_opinions = []\n",
    "    mixed_mined_opinions = []\n",
    "    negative_mined_opinions = []\n",
    "\n",
    "    for document in doc_result:\n",
    "        print(\"Document Sentiment: {}\".format(document.sentiment))\n",
    "        print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "            document.confidence_scores.positive,\n",
    "            document.confidence_scores.neutral,\n",
    "            document.confidence_scores.negative,\n",
    "        ))\n",
    "        for sentence in document.sentences:\n",
    "            print(\"Sentence: {}\".format(sentence.text))\n",
    "            print(\"Sentence sentiment: {}\".format(sentence.sentiment))\n",
    "            print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "                sentence.confidence_scores.positive,\n",
    "                sentence.confidence_scores.neutral,\n",
    "                sentence.confidence_scores.negative,\n",
    "            ))\n",
    "            for mined_opinion in sentence.mined_opinions:\n",
    "                aspect = mined_opinion.aspect\n",
    "                print(\"......'{}' aspect '{}'\".format(aspect.sentiment, aspect.text))\n",
    "                print(\"......Aspect score:\\n......Positive={0:.2f}\\n......Negative={1:.2f}\\n\".format(\n",
    "                    aspect.confidence_scores.positive,\n",
    "                    aspect.confidence_scores.negative,\n",
    "                ))\n",
    "                for opinion in mined_opinion.opinions:\n",
    "                    print(\"......'{}' opinion '{}'\".format(opinion.sentiment, opinion.text))\n",
    "                    print(\"......Opinion score:\\n......Positive={0:.2f}\\n......Negative={1:.2f}\\n\".format(\n",
    "                        opinion.confidence_scores.positive,\n",
    "                        opinion.confidence_scores.negative,\n",
    "                    ))\n",
    "            print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "          \n",
    "sentiment_analysis_with_opinion_mining_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_detection_example(client):\n",
    "    try:\n",
    "        documents = [\"Ce document est rédigé en Français.\"]\n",
    "        response = client.detect_language(documents = documents, country_hint = 'us')[0]\n",
    "        print(\"Language: \", response.primary_language.name)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "language_detection_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_recognition_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"I had a wonderful trip to Seattle last week.\"]\n",
    "        result = client.recognize_entities(documents = documents)[0]\n",
    "\n",
    "        print(\"Named Entities:\\n\")\n",
    "        for entity in result.entities:\n",
    "            print(\"\\tText: \\t\", entity.text, \"\\tCategory: \\t\", entity.category, \"\\tSubCategory: \\t\", entity.subcategory,\n",
    "                    \"\\n\\tConfidence Score: \\t\", round(entity.confidence_score, 2), \"\\tLength: \\t\", entity.length, \"\\tOffset: \\t\", entity.offset, \"\\n\")\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "entity_recognition_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_linking_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"\"\"Microsoft was founded by Bill Gates and Paul Allen on April 4, 1975, \n",
    "        to develop and sell BASIC interpreters for the Altair 8800. \n",
    "        During his career at Microsoft, Gates held the positions of chairman,\n",
    "        chief executive officer, president and chief software architect, \n",
    "        while also being the largest individual shareholder until May 2014.\"\"\"]\n",
    "        result = client.recognize_linked_entities(documents = documents)[0]\n",
    "\n",
    "        print(\"Linked Entities:\\n\")\n",
    "        for entity in result.entities:\n",
    "            print(\"\\tName: \", entity.name, \"\\tId: \", entity.data_source_entity_id, \"\\tUrl: \", entity.url,\n",
    "            \"\\n\\tData Source: \", entity.data_source)\n",
    "            print(\"\\tMatches:\")\n",
    "            for match in entity.matches:\n",
    "                print(\"\\t\\tText:\", match.text)\n",
    "                print(\"\\t\\tConfidence Score: {0:.2f}\".format(match.confidence_score))\n",
    "                print(\"\\t\\tOffset: {}\".format(match.offset))\n",
    "                print(\"\\t\\tLength: {}\".format(match.length))\n",
    "            \n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "entity_linking_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pii_recognition_example(client):\n",
    "    documents = [\n",
    "        \"The employee's SSN is 859-98-0987.\",\n",
    "        \"The employee's phone number is 555-555-5555.\"\n",
    "    ]\n",
    "    response = client.recognize_pii_entities(documents, language=\"en\")\n",
    "    result = [doc for doc in response if not doc.is_error]\n",
    "    for doc in result:\n",
    "        print(\"Redacted Text: {}\".format(doc.redacted_text))\n",
    "        for entity in doc.entities:\n",
    "            print(\"Entity: {}\".format(entity.text))\n",
    "            print(\"\\tCategory: {}\".format(entity.category))\n",
    "            print(\"\\tConfidence Score: {}\".format(entity.confidence_score))\n",
    "            print(\"\\tOffset: {}\".format(entity.offset))\n",
    "            print(\"\\tLength: {}\".format(entity.length))\n",
    "pii_recognition_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_phrase_extraction_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"My cat might need to see a veterinarian.\"]\n",
    "\n",
    "        response = client.extract_key_phrases(documents = documents)[0]\n",
    "\n",
    "        if not response.is_error:\n",
    "            print(\"\\tKey Phrases:\")\n",
    "            for phrase in response.key_phrases:\n",
    "                print(\"\\t\\t\", phrase)\n",
    "        else:\n",
    "            print(response.id, response.error)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "        \n",
    "key_phrase_extraction_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-brazilian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
